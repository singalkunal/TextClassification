{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os import path as path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "997"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting path for dataset\n",
    "dataset_path = './20_newsgroups/'\n",
    "len(listdir('20_newsgroups/soc.religion.christian/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19997"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading all documents in a particular class (newsgroup class)\n",
    "# as a separate list\n",
    "# listdir(d) lists the names of all files and directories present in directory d\n",
    "newsgroup_classes = listdir(dataset_path)\n",
    "\n",
    "# for each class append a list of documents in that class to all_docs\n",
    "all_docs = []\n",
    "for newsgroup_class in newsgroup_classes:\n",
    "    curr_class_path = path.join(dataset_path, newsgroup_class)\n",
    "#     print(curr_class_path)\n",
    "    all_docs.append(listdir(curr_class_path))\n",
    "\n",
    "# total docs available\n",
    "sum(len(all_docs[i]) for i in range(len(all_docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19997"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing paths of data\n",
    "all_docs_paths = []  # will store paths of all the documents\n",
    "Y = []  # will store newsgroup classes corresponding to each doc \n",
    "for class_index in range(len(all_docs)):\n",
    "    for doc in all_docs[class_index]:\n",
    "        all_docs_paths.append(path.join(path.join(dataset_path, newsgroup_classes[class_index]), doc))\n",
    "        Y.append(newsgroup_classes[class_index])\n",
    "print(len(Y))\n",
    "len(all_docs_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'to keep this as brief as possible, let me state my \\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(all_docs_paths[1], \"r\")\n",
    "# open('20_newsgroups/sci.med/')\n",
    "lines = (f.readlines())\n",
    "lines[15].lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Words -> commonly used words to be removed from the features list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['that', 'he', 'oursourselves', 'whither', 'least', 'me', 'until',\"let's\", 'by', 'con', 'them', 'alone', 'cry', 'fill', 'indeed',\n",
    "       'onto', 'nowhere', 'all', 'except', 'too', 'only', 'how','already', \"i've\", 'both', 'one', 'whose', 'further', 'while',\n",
    "       'nevertheless', 'next', 'part', 'upon', 'and', 'along', 'under','see', 'nor', \"she'd\", 'mill', 'perhaps', 'may', 'enough', \"we've\",\n",
    "       'former', 'anyone', 'behind', 'its', 'as', 'few', 'again',\"you'll\", 'nobody', 'each', 'my', 'anything', 'always', 'first',\n",
    "       'we', \"that's\", \"aren't\", 'hereupon', 'becoming', 'eg', 'co', 'go','then', 'system', 'however', 'often', 'such', \"weren't\", 'beside',\n",
    "       'therein', 'beforehand', 'am', 'latterly', 'put', \"she'll\", 'into', 'cannot', 'yet', 'about', 'seemed', 'many', 'within', 'over', 'so',\n",
    "       'those', 'these', 'namely', 'interest', 'own', 'for', 'besides', 'due', \"i'll\", 'himself', 'at', 'was', 'move', \"there's\", 'get',\n",
    "       'herself', 'seem', 'somehow', 'whereafter', 'somewhere', 'de',\"couldn't\", \"where's\", 'latter', 'fire', \"he'd\", \"haven't\",\n",
    "       'being', 'sometimes', 'hers', 're', 'whereas', 'during', 'or', 'bottom', 'together', 'when', 'were', 'very', 'whence', 'thru',\n",
    "       'to', \"didn't\", 'without', 'doing', 'other', 'toward', \"when's\",\"it's\", 'will', 'formerly', 'ours', 'thereupon', \"wasn't\", 'mine',\n",
    "       'theirs', 'whom', 'anyhow', 'per', 'anyway', 'noone', 'top','wherein', 'against', 'thereafter', 'ten', \"she's\", 'twelve',\n",
    "       'eleven', 'became', 'etc', 'six', 'but', 'amongst', 'having','detail', 'therefore', 'ltd', 'none', 'found', 'do', 'eight',\n",
    "       'forty', 'there', \"can't\", 'yourselves', 'two', 'everything',\"you're\", 'sincere', \"hasn't\", 'call', 'nothing', \"doesn't\", 'on',\n",
    "       'their', 'your', 'nine', 'around', 'same', 'either', 'yours','been', 'across', 'also', 'more', 'now', 'it', 'thick', 'fifteen',\n",
    "       'once', \"why's\", 'our', 'well', 'find', 'where', 'hasnt', 'up','among', 'seems', 'whenever', 'whoever', 'off', 'from', 'inc',\n",
    "       \"isn't\", 'thereby', 'throughout', 'is', 'otherwise', 'hereafter',\"they'd\", \"shan't\", 'ever', 'ie', 'has', 'be', 'amount',\n",
    "       'everyone', 'than', 'thus', 'sixty', 'neither', 'several', 'whole','cant', 'give', \"you've\", 'why', 'does', 'almost', \"we'll\", \"he's\",\n",
    "       'third', 'though', 'made', 'in', \"we'd\", 'themselves', 'after','out', 'serious', 'should', 'thin', 'via', 'twenty', 'would',\n",
    "       'ourselves', 'here', \"he'll\", 'couldnt', 'bill', 'whatever','describe', 'whereupon', 'his', 'name', 'below', 'every', 'myself',\n",
    "       'afterwards', \"you'd\", 'beyond', 'meanwhile', 'ought', 'because','yourself', 'no', 'us', \"how's\", 'with', 'they', 'which',\n",
    "       \"they've\", 'can', 'thence', 'are', 'even', 'everywhere', 'itself','have', 'some', 'back', 'sometime', \"shouldn't\", 'a', \"don't\",\n",
    "       'something', 'others', 'fifty', \"who's\", 'done', 'keep','wherever', 'before', 'between', 'above', 'else', 'herein',\n",
    "       'amoungst', 'someone', 'become', 'five', 'hence', 'hundred', 'you',\"we're\", 'anywhere', 'four', \"mustn't\", 'empty', 'this', \"i'm\",\n",
    "       'rather', 'whether', 'front', 'if', 'towards', 'although', 'could','side', 'three', \"wouldn't\", 'last', 'take', 'mostly', 'never',\n",
    "       'another', 'might', 'most', 'any', 'full', 'had', 'much', 'show','down', \"what's\", 'moreover', 'of', 'i', 'whereby', 'through',\n",
    "       'the', 'thousand', 'must', 'him', 'less', 'elsewhere', 'un','what', 'please', \"i'd\", 'her', 'she', 'since', \"won't\", \"hadn't\",\n",
    "       'an', 'still', 'hereby', 'seeming', \"they'll\", \"here's\", 'who',\"they're\", 'not', 'did', 'becomes', 'seven']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting of data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13997, 6000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "docs_train, docs_test, Y_train, Y_test = train_test_split(all_docs_paths, Y, test_size=0.3, random_state=0)\n",
    "len(docs_train), len(docs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords from given sequence by filtering out a word\n",
    "# if it exists in stop_word list\n",
    "def removeStopwords(sequence):\n",
    "    return list(filter(lambda word: word not in stop_words, sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func to remove numbers from list of words using regular expression(re)\n",
    "# \\d represents [0-9]\n",
    "import re\n",
    "def removeNumbers(words):\n",
    "    words = [re.sub(r\"\\d+\", \"\", word) for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my', 'name', 'is', 'kunal']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demo of removeNumbers()\n",
    "removeNumbers(['0my', 'na4m8e', 'is9', 'ku123nal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segmenting(or tokenizing) each line into words and preprocessing\n",
    "# remove punctuations and spaces and new line using tranlation\n",
    "# table (using maketrans)\n",
    "import string\n",
    "def tokenize_each_line(line):\n",
    "    line = line.translate(str.maketrans('', '', '\\n'))\n",
    "    line = line.translate(str.maketrans('', '', '\\t'))\n",
    "    punctuations_and_spaces = string.punctuation\n",
    "    line = line.translate(str.maketrans('', '', punctuations_and_spaces))\n",
    "    \n",
    "    # normalize\n",
    "    words = line.strip().lower().split()\n",
    "    \n",
    "    words = removeNumbers(words)\n",
    "    # removing empty word if any from words list\n",
    "    words = list(filter(lambda word: word != \"\", words))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my', 'name', 'is', 'kunal']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demo of tokenize_each_lines\n",
    "tokenize_each_line(\"\\nMy ~Na47me is Kunal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters metadata present on top of each document separated from rest\n",
    "# of the document by a empty line\n",
    "def remove_metadata(lines):\n",
    "    if len(lines) == 0:\n",
    "        return lines\n",
    "    metadata_end = 0  # will strore line no. of empty line\n",
    "    for i in range(len(lines)):\n",
    "        if lines[i] == '\\n':\n",
    "            metadata_end = i\n",
    "            break\n",
    "    return lines[metadata_end + 1 :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts 2d list into 1d list\n",
    "def flatten_list(llist):\n",
    "    new_list = []\n",
    "    for curr_list in llist:\n",
    "        for word in curr_list:\n",
    "            new_list.append(word)\n",
    "    return new_list        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segmentation(or tokenization) of particular doc => stores words present in current document\n",
    "# will help in building vocabulary\n",
    "def tokenize(curr_doc_path):\n",
    "    file = open(curr_doc_path, \"r\", encoding=\"latin1\")\n",
    "    all_lines_of_curr_doc = file.readlines()  # store list of lines in document\n",
    "    all_lines_of_curr_doc = remove_metadata(all_lines_of_curr_doc)  # remove metadata present on top of document\n",
    "\n",
    "    # tokenize each line\n",
    "    curr_doc_words = []\n",
    "    for line in all_lines_of_curr_doc:\n",
    "        curr_doc_words.append(tokenize_each_line(line))\n",
    "\n",
    "    final_list_of_words = flatten_list(curr_doc_words)   #convert 2d list into 1d\n",
    "    final_list_of_words = removeStopwords(final_list_of_words) #remove stop words from lists\n",
    "    return final_list_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demo of remove metadata\n",
    "remove_metadata(tokenize('20_newsgroups/soc.religion.christian/21612'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the words of each document as a\n",
    "# separate list in primary list i.e. doc_wise_words\n",
    "# i.e. resulting doc_wise_words is 2d list\n",
    "# all_words simply contains all words present in all the docs (flattened version of doc_wise_words)\n",
    "def extract_words(given_paths):\n",
    "    doc_wise_words = []\n",
    "    for path in given_paths:\n",
    "        doc_wise_words.append(tokenize(path))\n",
    "    all_words = flatten_list(doc_wise_words)\n",
    "    return doc_wise_words, all_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13997, 1682651)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting and storing words from training data (docs)\n",
    "doc_wise_words, all_words = extract_words(docs_train)\n",
    "len(doc_wise_words), len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['article', 'pqdhinnbmizephyrgracecrinz', 'srgsirgrvgracecrinz',\n",
       "       ..., 'evansmpcsastonacuk', 'x', 'office'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy array of all_words\n",
    "np_all_words = np.array(all_words, dtype = object)\n",
    "np_all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total features available and their frequencies\n",
    "tot_features, tot_features_freq = np.unique(np_all_words, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# freq of words and no. of words having that freq\n",
    "# helps in plotting graph and further building vocab\n",
    "f_of_words, n_of_words = np.unique(tot_features_freq, return_counts=True)\n",
    "len(f_of_words) == len(n_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2817b12e10>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel(\"No. of words\")\n",
    "plt.ylabel(\"freq of words\")\n",
    "plt.xlim(0, 400)\n",
    "plt.ylim(0, 100)\n",
    "plt.plot(f_of_words, n_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper func to sort list1 and list2 according to list2\n",
    "# zip() maps elements of same index in both lists\n",
    "# zip(*) unzips map into separate tupples\n",
    "# further converting each tupple into list and storing \n",
    "def sort_list(list1, list2):\n",
    "    zipped_pairs = zip(list2, list1)\n",
    "    sorted_list2, sorted_list1 = [list(tupple) for tupple in zip(*(sorted(zipped_pairs, reverse=True)))]\n",
    "    return sorted_list1, sorted_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122969"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorting\n",
    "tot_features_sorted, tot_features_freq_sorted  = sort_list(tot_features, tot_features_freq)\n",
    "len(tot_features_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using only \"top\" words as features\n",
    "top = 2000\n",
    "features = tot_features_sorted[:top]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcions to prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds dictionary of vocabulary of each document and stores frequencies for\n",
    "# each word in vocabularies of those documents\n",
    "def build_dictionary(doc_wise_words):\n",
    "    dictionary = {}\n",
    "    for doc_no in range(len(doc_wise_words)):\n",
    "        curr_doc = np.array(doc_wise_words[doc_no])\n",
    "        words, counts = np.unique(curr_doc, return_counts=True) # unique words present in current doc and their frequencies\n",
    "        dictionary[doc_no] = {}\n",
    "        for word_no in range(len(words)):\n",
    "            dictionary[doc_no][words[word_no]] = counts[word_no]\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stores frequency of each feature from set of features in each document in a numpy array\n",
    "# takes input a dictionary built using build_dictionary()\n",
    "def preparedata_from_dictionary(dictionary):\n",
    "    X = []\n",
    "    for doc_no in dictionary.keys():\n",
    "        curr_doc_list = []   # vocabulary of each document\n",
    "        for feature in features:\n",
    "            # if feature is present in vocabulary of current document update its freq\n",
    "            # else set it as 0\n",
    "            if feature in dictionary[doc_no].keys():\n",
    "                curr_doc_list.append(dictionary[doc_no][feature])\n",
    "            else:\n",
    "                curr_doc_list.append(0)\n",
    "        X.append(curr_doc_list)\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing training and testing data from paths given\n",
    "def prepare_training_data():\n",
    "    doc_wise_words,_ = extract_words(docs_train)\n",
    "    training_dict = build_dictionary(doc_wise_words)\n",
    "    X_train = preparedata_from_dictionary(training_dict)\n",
    "    print(\"X_train prepared successfully\")\n",
    "    \n",
    "    test_doc_wise_words, _ = extract_words(docs_test)\n",
    "    test_dict = build_dictionary(test_doc_wise_words)\n",
    "    X_test = preparedata_from_dictionary(test_dict)\n",
    "    print(\"X_test prepared successfully\")\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary of length  13997  built successfully\n",
      "Dictionary of length  6000  built successfully\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = prepare_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13997, 2000)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13997,), (6000,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = X_train[Y_train == 'rec.sport.hockey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 3, 4])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = np.array([[1 ,3 ,4], [0, 0, 0]])\n",
    "print(tt.shape)\n",
    "sum(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[curr_class] = sum(X__curr_class_train)\n",
    "result[curr_class][]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiNB Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# builds the dictionary which will be used to calc probabilities\n",
    "# during predict\n",
    "def fit(X_train, Y_train):\n",
    "    result = {}\n",
    "    result['tot_data'] = len(Y_train) # stores no. of data points (docs) present in training data\n",
    "    possible_classes = set(Y_train)\n",
    "    for curr_class in possible_classes:\n",
    "        result[curr_class] = {}\n",
    "        curr_class_rows = Y_train == curr_class  # logical array\n",
    "        X_curr_class_train = X_train[curr_class_rows] # rows having class == curr_class\n",
    "        Y_curr_class_train = Y_train[curr_class_rows]\n",
    "        result[curr_class]['tot_docs_curr_class'] = len(Y_curr_class_train) # storing no. of docs in current class\n",
    "        num_features = X_train.shape[1]\n",
    "        tot_words_curr_class = 0\n",
    "        # for each feature s\n",
    "        for j in range(1, num_features+1): \n",
    "            result[curr_class][j] = sum(X_curr_class_train[:, j-1])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training/fitting train data\n",
    "fitted_dict = fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tot_data', 'soc.religion.christian', 'talk.religion.misc', 'comp.os.ms-windows.misc', 'talk.politics.misc', 'rec.motorcycles', 'comp.sys.ibm.pc.hardware', 'talk.politics.mideast', 'rec.sport.baseball', 'sci.space', 'comp.sys.mac.hardware', 'sci.electronics', 'rec.sport.hockey', 'talk.politics.guns', 'misc.forsale', 'alt.atheism', 'sci.crypt', 'comp.graphics', 'rec.autos', 'comp.windows.x', 'sci.med'])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log probab for particular data point of belonging to curr_class\n",
    "# using bayes theorem\n",
    "# input dictionary is trained data\n",
    "def probability(x, dictionary, curr_class):\n",
    "    output = np.log(dictionary[curr_class]['tot_docs_curr_class']) - np.log(dictionary['tot_data'])\n",
    "    num_features = len(dictionary[curr_class].keys()) - 2\n",
    "    for j in range(1, num_features+1):\n",
    "        xj = x[j-1]\n",
    "        count_jth_word_curr_class = dictionary[curr_class][j] + 1 # count of jth word(feature) given curr_class\n",
    "        count_all_words_curr_class = dictionary[curr_class]['tot_words_curr_class'] + num_features # count of all words given curr_class\n",
    "        logp = np.log(count_jth_word_curr_class) - np.log(count_all_words_curr_class)\n",
    "        output += (xj * logp)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log probab for all data points of belonging to curr_class\n",
    "# using bayes theorem\n",
    "# input dictionary is trained data\n",
    "# returned output will be mX1 vector\n",
    "def probability2(X, dictionary, curr_class):\n",
    "    # for each i output[i] will store probablity of X[i] belonging to curr_class\n",
    "    output = (np.log(dictionary[curr_class]['tot_docs_curr_class']) - np.log(dictionary['tot_data'])) * np.ones(len(X)) # probab of curr_class P(curr_clss)\n",
    "    temp = np.array(list(dictionary[curr_class].values()))   # temp is temporary vector for vectorizing the process of finding probab\n",
    "    temp = np.delete(temp, [0]) # deleting values of 'tot_docs_curr_class'\n",
    "    count_all_words_curr_class = temp.sum()\n",
    "    \n",
    "    lg_num = np.log(temp + 1)\n",
    "    lg_den = np.log(count_all_words_curr_class * np.ones(len(temp)))\n",
    "    \n",
    "    logp = lg_num - lg_den\n",
    "    logp.reshape(-1);\n",
    "    output  += (X@logp)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test, dictionary):\n",
    "    classes = dictionary.keys()\n",
    "    best_p, best_class = np.zeros(len(X_test)), np.empty(len(X_test), dtype='U30') #sotres best probab and best class found so far\n",
    "    firstrun = True # bool for making sure best_p and best_class updates at first iteration\n",
    "    # for each class calc log probab of each doc belonging to that curr_class\n",
    "    # update best_p and best_p for docs(data points) for which curr_class is more \n",
    "    # probable than the best_class\n",
    "    for curr_class in classes:\n",
    "        if curr_class == 'tot_data':\n",
    "            continue\n",
    "        logp_of_curr_class = probability2(X_test, dictionary, curr_class) # mX1 vector\n",
    "        if firstrun:\n",
    "            best_p = logp_of_curr_class\n",
    "            best_class[True] = curr_class\n",
    "            firstrun = False\n",
    "        rows_with_better_p = (logp_of_curr_class > best_p) # logical array \n",
    "        best_p[rows_with_better_p] = logp_of_curr_class[rows_with_better_p]\n",
    "        best_class[rows_with_better_p] = curr_class\n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using MultiNB Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_data\n",
      "soc.religion.christian\n",
      "talk.religion.misc\n",
      "comp.os.ms-windows.misc\n",
      "talk.politics.misc\n",
      "rec.motorcycles\n",
      "comp.sys.ibm.pc.hardware\n",
      "talk.politics.mideast\n",
      "rec.sport.baseball\n",
      "sci.space\n",
      "comp.sys.mac.hardware\n",
      "sci.electronics\n",
      "rec.sport.hockey\n",
      "talk.politics.guns\n",
      "misc.forsale\n",
      "alt.atheism\n",
      "sci.crypt\n",
      "comp.graphics\n",
      "rec.autos\n",
      "comp.windows.x\n",
      "sci.med\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict2(X_test, fitted_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rec.sport.hockey', 'sci.electronics', 'rec.motorcycles', ...,\n",
       "       'sci.med', 'rec.motorcycles', 'talk.religion.misc'], dtype='<U30')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing predictions and comparing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing various classification measures and confusion matrix for both predicted data (Y_pred and y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.55      0.72      0.62       309\n",
      "           comp.graphics       0.65      0.65      0.65       319\n",
      " comp.os.ms-windows.misc       0.71      0.60      0.65       279\n",
      "comp.sys.ibm.pc.hardware       0.60      0.62      0.61       309\n",
      "   comp.sys.mac.hardware       0.62      0.71      0.66       298\n",
      "          comp.windows.x       0.82      0.76      0.79       287\n",
      "            misc.forsale       0.73      0.76      0.75       322\n",
      "               rec.autos       0.74      0.76      0.75       322\n",
      "         rec.motorcycles       0.77      0.86      0.81       296\n",
      "      rec.sport.baseball       0.80      0.85      0.83       284\n",
      "        rec.sport.hockey       0.89      0.87      0.88       294\n",
      "               sci.crypt       0.89      0.77      0.83       301\n",
      "         sci.electronics       0.61      0.65      0.63       297\n",
      "                 sci.med       0.80      0.78      0.79       287\n",
      "               sci.space       0.86      0.80      0.83       305\n",
      "  soc.religion.christian       0.70      0.80      0.75       273\n",
      "      talk.politics.guns       0.57      0.77      0.65       275\n",
      "   talk.politics.mideast       0.85      0.81      0.83       306\n",
      "      talk.politics.misc       0.66      0.56      0.60       308\n",
      "      talk.religion.misc       0.57      0.24      0.34       329\n",
      "\n",
      "                accuracy                           0.71      6000\n",
      "               macro avg       0.72      0.72      0.71      6000\n",
      "            weighted avg       0.72      0.71      0.71      6000\n",
      "\n",
      "[[223   3   0   1   0   0   0   3   3   2   0   0   1   6   3  28   7   5\n",
      "    7  17]\n",
      " [  2 207  23  17  18  13   8   2   5   0   0   2  11   6   2   0   2   1\n",
      "    0   0]\n",
      " [  2  19 168  40  14  13   2   2   2   2   0   1   6   1   2   1   3   1\n",
      "    0   0]\n",
      " [  2  10  23 192  40   5  11   3   0   0   1   2  15   2   1   0   1   0\n",
      "    0   1]\n",
      " [  0   4   5  25 213   1  15   1   5   4   0   1  16   6   0   0   1   0\n",
      "    1   0]\n",
      " [  0  27   9   8   8 218   4   0   2   1   0   0   2   1   1   0   5   0\n",
      "    0   1]\n",
      " [  1   2   2  14  19   3 245  10   1   1   4   2   9   1   2   1   5   0\n",
      "    0   0]\n",
      " [  2   1   0   1   2   1  10 244  20   2   2   0  19   1   3   0   4   0\n",
      "    8   2]\n",
      " [  2   0   0   1   1   1   7  17 255   3   0   0   4   1   1   0   2   0\n",
      "    1   0]\n",
      " [  0   4   0   1   1   2   5   1   3 241  19   0   1   3   1   0   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   1   0   2   4  21 257   1   2   1   0   3   0   0\n",
      "    2   0]\n",
      " [  1  10   1   2   4   4   1   1   7   2   1 232   3   2   3   0  12   0\n",
      "   12   3]\n",
      " [  1  12   4  16  17   1  18  16   3   3   0   7 194   1   1   1   2   0\n",
      "    0   0]\n",
      " [  5   8   0   0   1   2   1   4   4   2   1   1  13 225   5   0   5   2\n",
      "    5   3]\n",
      " [  5  10   1   0   1   1   3   7   4   5   2   1   9   2 243   1   5   0\n",
      "    3   2]\n",
      " [ 21   0   1   0   0   1   1   0   2   0   1   2   3   7   2 219   4   3\n",
      "    2   4]\n",
      " [  3   0   0   0   1   0   0   9   0   6   0   4   3   2   1   2 213   6\n",
      "   16   9]\n",
      " [ 10   1   0   0   3   0   4   2   2   1   0   1   1   2   2   6   5 248\n",
      "   14   4]\n",
      " [ 13   0   0   0   0   0   0   4   3   2   2   3   0   5   6   2  63  21\n",
      "  171  13]\n",
      " [114   2   1   0   0   0   0   3   6   2   0   1   4   7   3  50  35   4\n",
      "   18  79]]\n"
     ]
    }
   ],
   "source": [
    "# y_pred -> data predicted from own implementation\n",
    "# Y_pred ->data predicted form sklearn\n",
    "print(classification_report(Y_test,y_pred))\n",
    "print(confusion_matrix(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.55      0.71      0.62       309\n",
      "           comp.graphics       0.64      0.66      0.65       319\n",
      " comp.os.ms-windows.misc       0.70      0.60      0.65       279\n",
      "comp.sys.ibm.pc.hardware       0.60      0.62      0.61       309\n",
      "   comp.sys.mac.hardware       0.63      0.69      0.66       298\n",
      "          comp.windows.x       0.81      0.78      0.79       287\n",
      "            misc.forsale       0.76      0.75      0.75       322\n",
      "               rec.autos       0.73      0.75      0.74       322\n",
      "         rec.motorcycles       0.78      0.85      0.81       296\n",
      "      rec.sport.baseball       0.81      0.85      0.83       284\n",
      "        rec.sport.hockey       0.89      0.88      0.89       294\n",
      "               sci.crypt       0.86      0.78      0.82       301\n",
      "         sci.electronics       0.63      0.66      0.64       297\n",
      "                 sci.med       0.78      0.78      0.78       287\n",
      "               sci.space       0.85      0.79      0.82       305\n",
      "  soc.religion.christian       0.69      0.81      0.74       273\n",
      "      talk.politics.guns       0.56      0.78      0.65       275\n",
      "   talk.politics.mideast       0.85      0.82      0.83       306\n",
      "      talk.politics.misc       0.64      0.56      0.60       308\n",
      "      talk.religion.misc       0.58      0.24      0.34       329\n",
      "\n",
      "                accuracy                           0.71      6000\n",
      "               macro avg       0.72      0.72      0.71      6000\n",
      "            weighted avg       0.72      0.71      0.71      6000\n",
      "\n",
      "[[220   3   0   1   0   0   0   3   2   0   0   1   1   7   3  29   8   6\n",
      "    8  17]\n",
      " [  2 209  21  18  17  14   6   2   3   0   0   4  10   6   3   0   3   1\n",
      "    0   0]\n",
      " [  2  20 167  40  13  15   1   2   2   2   0   2   6   0   2   1   3   1\n",
      "    0   0]\n",
      " [  2  13  23 192  39   5  10   3   0   0   1   2  14   2   1   0   1   0\n",
      "    0   1]\n",
      " [  1   6   6  27 207   1  12   2   3   5   0   2  16   6   1   0   1   0\n",
      "    1   1]\n",
      " [  0  25  10   8   6 223   2   1   1   1   0   1   1   1   1   0   5   0\n",
      "    0   1]\n",
      " [  1   4   2  14  18   3 240  12   1   1   2   3   9   2   3   1   5   0\n",
      "    1   0]\n",
      " [  2   1   0   1   2   1  10 241  20   2   2   0  18   2   3   0   7   0\n",
      "    8   2]\n",
      " [  2   0   0   1   1   1   7  19 251   4   0   0   4   1   1   1   2   0\n",
      "    1   0]\n",
      " [  0   4   1   1   1   2   3   1   4 241  19   0   1   3   1   0   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   1   0   2   4  19 258   1   2   1   0   3   0   0\n",
      "    2   1]\n",
      " [  1   8   1   2   3   4   1   1   6   2   1 236   3   3   3   0  12   0\n",
      "   13   1]\n",
      " [  1  12   4  17  16   2  15  15   4   3   0   7 195   1   1   2   2   0\n",
      "    0   0]\n",
      " [  5   9   0   0   0   2   1   4   3   2   1   2  13 225   5   0   5   2\n",
      "    5   3]\n",
      " [  6  12   0   0   1   1   2   5   4   5   2   1   7   4 242   1   6   0\n",
      "    4   2]\n",
      " [ 19   0   1   0   0   1   1   0   2   0   1   2   3   7   2 221   4   3\n",
      "    2   4]\n",
      " [  3   0   0   0   1   0   0   7   0   5   0   4   3   2   1   2 214   6\n",
      "   18   9]\n",
      " [  9   0   0   0   3   0   4   1   2   1   0   1   1   3   2   6   6 250\n",
      "   14   3]\n",
      " [ 13   0   0   0   0   0   0   4   3   2   2   3   0   5   6   2  62  21\n",
      "  172  13]\n",
      " [112   2   1   0   0   0   0   3   6   2   0   1   3   6   3  53  36   4\n",
      "   18  79]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,Y_pred))\n",
    "print(confusion_matrix(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n",
      "Same classes predicted for:  5891  docs\n"
     ]
    }
   ],
   "source": [
    "print(len(y_pred))\n",
    "print(\"Same classes predicted for: \", (y_pred == Y_pred).sum(), \" docs\")\n",
    "\n",
    "# data predicted is almost same"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
